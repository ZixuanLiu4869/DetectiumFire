# DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and Language for Fire Understanding

DetectiumFire is a large-scale, multi-modal dataset designed to advance fire understanding in both traditional computer vision and modern vision-language tasks. 
It provides high-quality real and synthetic fire data, detailed annotations, and human preference feedback for training and evaluating object detectors, diffusion models, and vision-language models (VLMs). 
The whole dataset can be found at https://www.kaggle.com/datasets/38b79c344bdfc55d1eed3d22fbaa9c31fad45e27edbbe9e3c529d6e5c4f93890.
The associated models, such as object detectors (e.g., YOLO families), diffusion models (e.g., Stable Diffusion) can be found at ?
This repo contains the codes for processing our dataset for training, information regarding training the related models and the meta data of the dataset.


We will iterative updates our dataset and estimate to introduce DetectiumFire-Plus, which will include more recent fire-related images. We welcome community feedback to grow DetectiumFire in both scale and impact!






Please cite our work if it is helpful:

@inproceedings{
liu2025detectiumfire,
title={DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and Language for Fire Understanding},
author={Zixuan Liu and Siavash H. Khajavi and Guangkai Jiang},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2025},
url={https://openreview.net/forum?id=vhHYTjMt9Z}
}
